{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuralNetwork Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_cg\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, X, y):\n",
    "        # layers is a list consisting of no. of neurons in each layer\n",
    "        # bias neuron is NOT included\n",
    "        # bias neuron is taken care of in init_weights_randomized method\n",
    "        # e.g.: layers = [400, 16, 16, 10]\n",
    "        self.layers = layers\n",
    "        self.L = len(layers)\n",
    "        self.X_not_biased = X\n",
    "        self.optimum_weights = None\n",
    "\n",
    "        self.m = self.X_not_biased.shape[0]\n",
    "        self.n = self.X_not_biased.shape[1]\n",
    "        self.y = y.reshape(self.m, 1)\n",
    "\n",
    "        bias = np.ones((self.m, 1))\n",
    "        self.X_biased = np.append(bias, self.X_not_biased, axis=1)\n",
    "        self.weights = self.init_weights_randomized()\n",
    "        # self.weights_vector = self.unroll(self.weights)\n",
    "\n",
    "    def train(self):\n",
    "        thetavec = self.unroll_list_of_matrices(self.weights)\n",
    "        xvec = self.unroll_X_matrix(self.X_not_biased)\n",
    "\n",
    "        result = minimize(method='CG', fun=self.cost, jac=self.back_propagate, x0=thetavec, args=(xvec, self.y, 1), options={'maxiter': 50})",
    "\n",
    "        rows = result.x.size\n",
    "        self.optimum_weights = self.roll_weights(result.x.reshape(rows, 1))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_prime(self, z):\n",
    "        # np.multiply(): element-wise multiplication\n",
    "        return np.multiply(self.sigmoid(z), 1 - self.sigmoid(z))\n",
    "\n",
    "    def init_weights_randomized(self):\n",
    "        # if we have L layers, we are going to have L-1 weight matrices\n",
    "        # this method returns a 'list' of weight matrices\n",
    "        result = []\n",
    "        for i in range(0, self.L - 1):\n",
    "            matrix = np.random.random((self.layers[i+1], 1 + self.layers[i]))\n",
    "            matrix = 2 * matrix - 1\n",
    "            result.append(matrix)\n",
    "        return result\n",
    "\n",
    "    def unroll_list_of_matrices(self, matrices):\n",
    "        mylist = []\n",
    "        size = 0\n",
    "        for i in range(len(matrices)):\n",
    "            size += matrices[i].shape[0] * matrices[i].shape[1]\n",
    "            mylist.append(list(matrices[i].ravel()))\n",
    "        for i in range(1, len(mylist)):\n",
    "            mylist[0] = mylist[0] + mylist[i]\n",
    "        return np.array(mylist[0]).reshape(size, 1)\n",
    "\n",
    "    def unroll_X_matrix(self, X_matrix):\n",
    "        size = X_matrix.shape[0] * X_matrix.shape[1]\n",
    "        return X_matrix.reshape(size, 1)\n",
    "\n",
    "    def roll_weights(self, weights_vector):\n",
    "        # this function gets the unrolled-vector and returns matrix(s)\n",
    "        result = []\n",
    "        start = 0\n",
    "        # just to make sure it's a vector\n",
    "        weights_vector = weights_vector.reshape(weights_vector.size, 1)\n",
    "        for i in range(self.L - 1):\n",
    "            shape = (self.layers[i+1], 1 + self.layers[i])\n",
    "            no = shape[0] * shape[1]\n",
    "            end = no + start\n",
    "            cur = weights_vector[start:end, ...].reshape(shape)\n",
    "            start = end\n",
    "            result.append(cur)\n",
    "        return result\n",
    "\n",
    "    def roll_X(self, X_vector):\n",
    "        return np.array(X_vector).reshape(self.m, self.n)\n",
    "\n",
    "    def feed_forward(self, x_vector, weights):\n",
    "        # this function gets a specific vector, and returns activations ...\n",
    "        # of neural network to the vector\n",
    "        # x_vector is biased INSIDE this function\n",
    "        # so there is NO NEED to add the bias before passing to this function\n",
    "        zs_activations = [(x_vector, x_vector)]\n",
    "        vector = x_vector.reshape(self.n, 1)\n",
    "        cur_vector = vector\n",
    "        bias = np.array([[1]])\n",
    "        for weight_matrix in weights:\n",
    "            i = weights.index(weight_matrix)\n",
    "            # add the bias:\n",
    "            cur_vector = np.append(bias, cur_vector)\n",
    "            cur_vector = cur_vector.reshape(1 + self.layers[i], 1)\n",
    "            z = np.matmul(weight_matrix, cur_vector)\n",
    "            a = self.sigmoid(z)\n",
    "            cur_vector = a\n",
    "            zs_activations.append((z, a))\n",
    "\n",
    "        return zs_activations\n",
    "\n",
    "    def refine_y(self, y_value):\n",
    "        # this funcion receives a value of y ...\n",
    "        # and returns a vector which has only 1 nonzero value\n",
    "        # dimension of the returned vector is equal to number of classes\n",
    "        result = np.zeros((self.layers[self.L - 1], 1))\n",
    "        result[y_value][0] = 1\n",
    "        return result\n",
    "\n",
    "    def cost(self, weights_vector, X_vector, y, lmd):\n",
    "        X = self.roll_X(X_vector)\n",
    "        weights = self.roll_weights(weights_vector)\n",
    "        cost = 0\n",
    "        for i in range(self.m):\n",
    "            x_vector = X[i].reshape((self.n, 1))\n",
    "            activations = self.feed_forward(x_vector, weights)\n",
    "            hypothesis = activations[-1][1]\n",
    "            my_y = self.refine_y(y[i][0])\n",
    "            cost += np.matmul(my_y.T, np.log(hypothesis))\n",
    "            cost += np.matmul((1 - my_y).T, np.log(1 - hypothesis))\n",
    "        cost *= (-1 / self.m)\n",
    "\n",
    "        # regularization term\n",
    "        reg = 0\n",
    "        if lmd != 0:\n",
    "            for weight_matrix in weights:\n",
    "                reg += np.sum(np.multiply(weight_matrix, weight_matrix))\n",
    "            reg *= lmd / (self.m * 2)\n",
    "\n",
    "        return cost + reg\n",
    "\n",
    "    def back_propagate(self, weights_vector, X_vector, y, lmd):\n",
    "        weights_matrices = self.roll_weights(weights_vector)\n",
    "        X = self.roll_X(X_vector)\n",
    "        deltas = [None for i in range(0, self.L)]\n",
    "        # deltas[0] is never used\n",
    "        Deltas = []\n",
    "        Ds = []\n",
    "        # Deltas[L-1] is never used\n",
    "        for i in range(0, self.L - 1):\n",
    "            shape = (self.layers[i + 1], 1 + self.layers[i])\n",
    "            Deltas.append(np.zeros(shape))\n",
    "            Ds.append(np.zeros(shape))\n",
    "\n",
    "        for i in range(0, self.m):\n",
    "            x_vector = X[i].reshape(self.n, 1)\n",
    "            zs_activations = self.feed_forward(x_vector, weights_matrices)\n",
    "            deltas[-1] = zs_activations[-1][1] - self.refine_y(y[i][0])\n",
    "            for j in range(self.L - 2, 0, -1):\n",
    "                deltas[j] = np.matmul(weights_matrices[j].T, deltas[j+1])\n",
    "                # elementwise multiplication:\n",
    "                deltas[j][1:, ...] *= self.sigmoid_prime(zs_activations[j][0])\n",
    "                # remove the bias:\n",
    "                deltas[j] = deltas[j][1:, ...]\n",
    "\n",
    "            for j in range(0, self.L - 1):\n",
    "                activation = zs_activations[j][1]\n",
    "                bias = np.array([[1]])\n",
    "                activation = np.append(bias, activation)\n",
    "                activation = activation.reshape(1 + self.layers[j], 1)\n",
    "                Deltas[j] += np.matmul(deltas[j+1], activation.T)\n",
    "\n",
    "        for i in range(0, self.L-1):\n",
    "            Ds[i] = Deltas[i] / self.m\n",
    "            if lmd != 0:\n",
    "                Ds[i][..., 1:] += (lmd / self.m) * weights_matrices[i][..., 1:]\n",
    "\n",
    "        Deltas = self.unroll_list_of_matrices(Deltas)\n",
    "\n",
    "        # for scipy, we need 1-D arrays as gradient\n",
    "        return np.ndarray.flatten(Deltas)\n",
    "\n",
    "    def get_accuracy(self):\n",
    "        corrects = 0\n",
    "        for i in range(0, self.m):\n",
    "            x_vec = self.X_not_biased[i].reshape(self.layers[0], 1)\n",
    "            final_activation = self.feed_forward(x_vec, self.optimum_weights)[-1][1]\n",
    "            mylist = list(final_activation.ravel())\n",
    "            maximum = max(mylist)\n",
    "            idx = mylist.index(maximum)\n",
    "            if idx == self.y[i][0]:\n",
    "                corrects += 1\n",
    "        return 100 * corrects / self.m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.819525\n",
      "         Iterations: 45\n",
      "         Function evaluations: 529\n",
      "         Gradient evaluations: 529\n",
      "Accuracy:  94.76\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "X = sio.loadmat('ex3data1.mat')['X']\n",
    "y = sio.loadmat('ex3data1.mat')['y']\n",
    "for i in range(y.shape[0]):\n",
    "    if y[i][0] == 10:\n",
    "        y[i][0] = 0\n",
    "\n",
    "\n",
    "nn = NeuralNetwork([400, 25, 10], X, y)\n",
    "nn.train()\n",
    "print('Accuracy: ', nn.get_accuracy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
